## Pandas Formats Profiling


Run
```bash
pip install -r requirements.txt
```

We benchmarked 6 different file formats for storing pandas dataframes. The formats are: CSV, Parquet, HDF5, Feather, NPY, and Excel.


| Format   | Save Time (s) | Load Time (s) | File size |
|----------|---------------|---------------|-----------|
| CSV      | 32.19560      | 5.61545       | 936.09 MB |
| Excel    | 512.45685     | 270.20350     | 622.33 MB |
| Parquet  | 1.56897       | 0.14528       | 394.84 MB |
| HDF5     | 0.12157       | 0.38918       | 389.11 MB |
| Feather  | 0.36712       | 0.11358       | 381.57 MB |
| NPY      | 0.05290       | 0.05778       | 381.47 MB |


We tested a tubular dataset with 100,000 rows and 50 columns in np.float. 
Based on the results, the best format for saving and loading pandas dataframes is NPY. It is the fastest and has the smallest file size.


## Single/Multi Process/Thread Profiling

We benchmarked performance of inference a lightweight yolov5 model on a CPU using single and multi process/thread and RAY.

We results we got:

Single process: 4.42 seconds
MultiProcessing: 8.73 seconds
MultiThreading: 3.35 seconds
Ray: 7.04 seconds
| Type   |  Time (s) |
|----------|--------|
| Single process  | 4.42 |
| MultiProcessing | 8.73 |
| MultiThreading  | 3.35  |
| Ray | 7.04 |


Usage:
```bash
python model_benchmark/model_benchmark.py --image_directory /path/to/images --batch_size <int>
```


## Streaming 
Developed code is for YOLO like image dataset

```bash
export AWS_ACCESS_KEY_ID=<key>
export AWS_SECRET_ACCESS_KEY=<key>

python create_streaming_dataset.py --yolo_dir /path/to/yolo/dataset --output_dir /path/to/output/dataset
aws s3 cp --recursive /path/to/output/dataset s3://<bucket_name>/path/to/output/dataset
```

For reeading the dataset, pass the needed parameters to the `read_streaming_dataset.py` script and use the dataloader from it.
    
```bash
python read_streaming_dataset.py --local <local> --remote <remote> --batch_size <int>
```